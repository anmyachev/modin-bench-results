{"project": "modin", "project_url": "https://modin.readthedocs.io/", "show_commit_url": "https://github.com/modin-project/modin/commit/", "hash_length": 8, "revision_to_hash": {"29": "45be5033b1d8578bd9af39ac18a973054bb46c21", "44": "cc47fdd73684b50397da91694be2351ab1bc3175", "52": "cccea0bed17349727ba13376ee7cc62ac5619852", "103": "26833bb8e7c1dcbab348c63ae9ad88d98c21c4de", "119": "acf323c9d56b779d6b71b4facf70bb1392c775d0", "142": "afff86c6f75af0b6b2427faa7398ca68a5edf466", "147": "a0dd74299f03e362f41f9c7c629a8e345e665bc7", "159": "8d4efd0ce85a4f7297b344ad691f78ee355daf23", "233": "0c218246a97f09cfc3fdc90926230dd2a1b1934a", "246": "79c111337ef2d0f6240821619a70e4583cf846d0", "269": "ff8960e1aeada95d3e09cd30bcd53e386b56ecaf", "278": "50a7a27b9ca7ad82ef43163053c4b37fc2793b6c", "284": "7ee7a98496328a450e6854f5e78cdfcd06a260e8", "343": "09ff0c2e4e28e01c2625c05d9a23fd043c693b96", "356": "2ab1170df4a6e8ae4ca9d5a51554f921884794e9", "359": "c1c985ae179ee425c637021efb1cb31fc719970e", "380": "588272bf2c9811cbfd08da810a5b2ec7f83e65c0", "406": "a351907e94e44027a56afe008171e3396370681d", "428": "ac2c9da232efad0a0066698f65804f01681e7986", "444": "3caf783d5ad4501c0489c088b7bb2fa5a54f128b", "457": "cf7be8c9eaf6732a0d3240aebbf5f40982002e36", "478": "9966f6821155285b784b0670cb4e1b91a243b63d", "554": "6aac82bc06d8fd57d603d11ca62a966973839610", "582": "90191f115e0ad57394598551fd2fd2ee8f70ed43", "589": "9e1b699dc129140be2fd6e9276bbe090fe7c06ab", "696": "27b68f2cb91fa9d435152b873e3437a22ae7c709", "1301": "4d35e7076a938b2cc327ce8d6e1922dd69bcff00", "1518": "03a919eab67492a5e41ecc712051beb37c75598b", "2052": "5b6f73a98cc0ee5a78503704b98b7268709dc797", "2055": "0e200c6219547ec20aad43718d5ec6d3ea501a3b", "2302": "3395b595d5bb460fecfd706c7d098b4610c9c9dd", "2335": "5c9398c23da933043045cb9636e19216f834ae2d", "2339": "86ebc316b8aeda692f5e2abee4e7c64ec74a2697", "2341": "1da519858cfd1d265d01bfa65a5aaac8c40726cd", "2380": "f7f1f7ac553dc3cc6595204fb7566db0e8f7f85f", "2384": "0c40d61646b00393ce6a9ffaeac75878c77c64eb", "2419": "c863b3d5afe8a84734ad4b325c949cafd4bb2bc5", "2530": "ebbb6b27df2703c27b85f5730e0344f6dd813897", "2547": "787d2b1cb40db80a43bdb0dd77c021f5d2dbb01a", "2548": "da83b62142944985acb571829a2dad9afbc49ecd", "2550": "f98a7b3a741a13ef4a2c25b5a2375475dea4e3bf", "2556": "d13fe74d452af2dcefa762a4b5e76f26157a568d", "2616": "bcab1cc903151a7fa52dca7c90730fcf12f04ab7", "2626": "477c5f689d08c851feb669ab6a81b4983db0cc57", "2628": "7cfc85c311fbe91c653285c46639352dd9ae4321", "2630": "d6637304a24f986b5abb12e2b525bc3af97d6cac", "2635": "4292d55121b6d93d51b4af27637b0bf9402984cc", "2636": "d720579bfa35bc322f11907c4511eb3ccf57fbd9", "2637": "01fbe9fb12d1ac7d13761d359d3d58cb6346a167", "2639": "6d420fbd74fa62934cacd50791fffe4338ca48da", "2641": "5f03eb8b1e887f9f3b6990fb023576070d0e6cee", "2653": "199666638bbc0f3950fa526c3889be011d567bfa", "2655": "fb94254f4a43e15c8c22e57caf3071979d9fbb4d", "2659": "2f880c1c93b05dbcaf8120ef6bb75a6adfa2e8e5", "2667": "ad55231c29be7f5e9ead1364e564e81be400fe97", "2671": "31d063276c19732f090dff71e5aa438ddac0a6f9", "2678": "6caa7b4a60e516bde2f6295d7bdb78919f15acce", "2679": "4f26fc1260717907ade24973a9c5a064a6810c85", "2680": "09d7c180f603a3079ef9aceb50ac6fdd2cb56bbe", "2681": "f2a7271d555b8909fdb88e951ffc4f110bb7529c", "2691": "03ea9b2c3728a83cd9247a89b72677409cdc7dfd", "2695": "9cb165dd889b9507820c84532b5ba613ac5edb9a", "2701": "e99b629da1a6748c5d675a2d904fcd943cd5964b", "2705": "5ad5fa352d133cc84a3f8cf09c9dc41d824444a0", "2706": "3e1258f83fcd704def172daff3c6e0090a9c039a", "2759": "90e118305aa829f51d776085aee0cd9921c30346", "2760": "77d40ce26a0052a9739a677521efd0b5b9d8048c", "2801": "16fa188219a20cc18a57bf03e7374f4260983c78", "2802": "0f4ce8a585e5ac10c714267d40f728c3ecf2e205", "2803": "5990e069136a5a12f56997d354d1577279824d0f", "2860": "a2ecf3190dad78e43f77d6132d835ef22dfb3382", "2863": "7935c59a94fafc7a975d62809c04a32a6c05c98f", "2869": "8ebbad9bca36aba0ddfc58dac89b9a66b0bfe41a", "2892": "1f3b514cbc019ece28a89d66f27584db30759888", "2893": "ad0bcaba488f87eba1120ae75981f1b5d24eb0ed", "2927": "c9a8c9cd3f78ec8af03c5e238c8085c79cc3ad5d", "2933": "d390f56afeabb7238a7b39f215a163e04e162d1f", "2948": "f9cf1403bae47a5eff774aadd1574d1c578065a3", "2963": "07f1cc79931bb94b1836cdbbe423a86cf6feafa2", "2976": "954f84a205597e2f198024b4fd83d1ff75940016", "3035": "77c9d1f72bd9fe497cb159d8e67b84a35210d2e5", "3065": "be33e95a4f35051afc683e187518a3ada6df95a2", "3093": "3652d19ce6768f9cb739f784d4c96d0d2d55ea06", "3096": "6f983ef0c855b9bb39df1803e6a4369bb0322b6e"}, "revision_to_date": {"29": 1530958932000, "44": 1532832060000, "52": 1537217633000, "103": 1539706572000, "119": 1540489521000, "142": 1541914566000, "147": 1542344110000, "159": 1543783281000, "233": 1547191609000, "246": 1548355112000, "269": 1549573658000, "278": 1551152349000, "284": 1551927428000, "343": 1557116901000, "356": 1559055183000, "359": 1559317856000, "380": 1560910205000, "406": 1563339307000, "428": 1567400441000, "444": 1569029417000, "457": 1571246222000, "478": 1574055162000, "554": 1579676141000, "582": 1582587141000, "589": 1583521430000, "696": 1588098607000, "1301": 1594058570000, "1518": 1596062677000, "2052": 1601507094000, "2055": 1601563997000, "2302": 1604963155000, "2335": 1605297257000, "2339": 1605364249000, "2341": 1605382714000, "2380": 1606155597000, "2384": 1606305626000, "2419": 1606828913000, "2530": 1607599567000, "2547": 1608046374000, "2548": 1608048806000, "2550": 1608070294000, "2556": 1608145598000, "2616": 1610458811000, "2626": 1610532523000, "2628": 1610550176000, "2630": 1610573697000, "2635": 1610665006000, "2636": 1610697877000, "2637": 1610702623000, "2639": 1610721846000, "2641": 1610725443000, "2653": 1611063894000, "2655": 1611130571000, "2659": 1611167988000, "2667": 1611566450000, "2671": 1611747254000, "2678": 1611845667000, "2679": 1611847668000, "2680": 1611867387000, "2681": 1611918072000, "2691": 1612100187000, "2695": 1612207852000, "2701": 1612274176000, "2705": 1612305613000, "2706": 1612305855000, "2759": 1612424120000, "2760": 1612424188000, "2801": 1612529045000, "2802": 1612544520000, "2803": 1612555682000, "2860": 1613392408000, "2863": 1613404117000, "2869": 1613491688000, "2892": 1613656390000, "2893": 1613658575000, "2927": 1614000339000, "2933": 1614182257000, "2948": 1614345007000, "2963": 1614619675000, "2976": 1614711697000, "3035": 1614864975000, "3065": 1614897335000, "3093": 1615235108000, "3096": 1615319792000}, "params": {"arch": ["x86_64"], "cpu": ["Intel(R) Xeon(R) CPU E5-2699 v4 @ 2.20GHz"], "machine": ["xeon-e5"], "num_cpu": ["44"], "os": ["Linux 5.4.0-54-generic"], "ram": ["131910328"], "python": ["3.8"], "branch": ["master"]}, "graph_param_list": [{"arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2699 v4 @ 2.20GHz", "machine": "xeon-e5", "num_cpu": "44", "os": "Linux 5.4.0-54-generic", "ram": "131910328", "python": "3.8", "branch": "master"}], "benchmarks": {"benchmarks.TimeAppend.time_append": {"code": "class TimeAppend:\n    def time_append(self, shapes, sort):\n        execute(self.df1.append(self.df2, sort=sort))\n\n    def setup(self, shapes, sort):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )\n        if sort:\n            self.df1.columns = self.df1.columns[::-1]", "min_run_count": 2, "name": "benchmarks.TimeAppend.time_append", "number": 0, "param_names": ["shapes", "sort"], "params": [["((5000, 5000), (5000, 5000))", "((500000, 20), (1000000, 10))"], ["False", "True"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c2d89eb99a9d7965ff21009a90377a267577d695e1baeeedba0a97d62f2f8030", "warmup_time": -1}, "benchmarks.TimeArithmetic.time_apply": {"code": "class TimeArithmetic:\n    def time_apply(self, shape, axis):\n        execute(self.df.apply(lambda df: df.sum(), axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)", "min_run_count": 2, "name": "benchmarks.TimeArithmetic.time_apply", "number": 0, "param_names": ["shape", "axis"], "params": [["(5000, 5000)", "(1000000, 10)"], ["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "219317b7fcbaf3f87050bca6999e1b68c258853598a859ac59da82b025bf251a", "warmup_time": -1}, "benchmarks.TimeArithmetic.time_mean": {"code": "class TimeArithmetic:\n    def time_mean(self, shape, axis):\n        execute(self.df.mean(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)", "min_run_count": 2, "name": "benchmarks.TimeArithmetic.time_mean", "number": 0, "param_names": ["shape", "axis"], "params": [["(5000, 5000)", "(1000000, 10)"], ["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b541392002bd635e8fdf6d069d1fb9147bf2e0d1cbccf130bf1b596c17454708", "warmup_time": -1}, "benchmarks.TimeArithmetic.time_median": {"code": "class TimeArithmetic:\n    def time_median(self, shape, axis):\n        execute(self.df.median(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)", "min_run_count": 2, "name": "benchmarks.TimeArithmetic.time_median", "number": 0, "param_names": ["shape", "axis"], "params": [["(5000, 5000)", "(1000000, 10)"], ["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6f99b2ce6d39b39818206977c6513e7df8166e01bbff37724a82601a9c4875ad", "warmup_time": -1}, "benchmarks.TimeArithmetic.time_nunique": {"code": "class TimeArithmetic:\n    def time_nunique(self, shape, axis):\n        execute(self.df.nunique(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)", "min_run_count": 2, "name": "benchmarks.TimeArithmetic.time_nunique", "number": 0, "param_names": ["shape", "axis"], "params": [["(5000, 5000)", "(1000000, 10)"], ["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e6aa9b726c293d7e2d3121d8ad006add467a8da0531eac8774b3f0384ca64bc", "warmup_time": -1}, "benchmarks.TimeArithmetic.time_sum": {"code": "class TimeArithmetic:\n    def time_sum(self, shape, axis):\n        execute(self.df.sum(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)", "min_run_count": 2, "name": "benchmarks.TimeArithmetic.time_sum", "number": 0, "param_names": ["shape", "axis"], "params": [["(5000, 5000)", "(1000000, 10)"], ["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3ade96bfe969295a9d3c99d61bc88dedda36a799925710d5620e5fb30438d074", "warmup_time": -1}, "benchmarks.TimeAstype.time_astype": {"code": "class TimeAstype:\n    def time_astype(self, shape, dtype, astype_ncolumns):\n        execute(self.df.astype(self.astype_arg))\n\n    def setup(self, shape, dtype, astype_ncolumns):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        if astype_ncolumns == \"all\":\n            self.astype_arg = dtype\n        elif astype_ncolumns == \"one\":\n            self.astype_arg = {\"col1\": dtype}\n        else:\n            raise ValueError(\"astype_ncolumns: {astype_ncolumns} isn't supported\")", "min_run_count": 2, "name": "benchmarks.TimeAstype.time_astype", "number": 0, "param_names": ["shape", "dtype", "astype_ncolumns"], "params": [["(5000, 5000)", "(1000000, 10)"], ["'float64'", "'category'"], ["'one'", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e0815604b1644fa44789102d06d841ad6e2d03792cc5d694a40c0838ae3275f3", "warmup_time": -1}, "benchmarks.TimeBinaryOp.time_binary_op": {"code": "class TimeBinaryOp:\n    def time_binary_op(self, shapes, binary_op, axis):\n        execute(self.op(self.df2, axis=axis))\n\n    def setup(self, shapes, binary_op, axis):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )\n        self.op = getattr(self.df1, binary_op)", "min_run_count": 2, "name": "benchmarks.TimeBinaryOp.time_binary_op", "number": 0, "param_names": ["shapes", "binary_op", "axis"], "params": [["((5000, 5000), (5000, 5000))", "((500000, 20), (1000000, 10))"], ["'mul'"], ["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9ff776f725432c65f49e1c3f59022f6f3d976278510bf9915fda51ba51ad13ae", "warmup_time": -1}, "benchmarks.TimeConcat.time_concat": {"code": "class TimeConcat:\n    def time_concat(self, shapes, how, axis):\n        execute(IMPL[ASV_USE_IMPL].concat([self.df1, self.df2], axis=axis, join=how))\n\n    def setup(self, shapes, how, axis):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )", "min_run_count": 2, "name": "benchmarks.TimeConcat.time_concat", "number": 0, "param_names": ["shapes", "how", "axis"], "params": [["((5000, 5000), (5000, 5000))", "((500000, 20), (1000000, 10))"], ["'inner'"], ["0", "1"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "718c07f0450388e6f586cf10e7466f364cc94e4a6909380b7f50d8213c45205c", "warmup_time": -1}, "benchmarks.TimeDescribe.time_describe": {"code": "class TimeDescribe:\n    def time_describe(self, shape):\n        execute(self.df.describe())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)", "min_run_count": 2, "name": "benchmarks.TimeDescribe.time_describe", "number": 0, "param_names": ["shape"], "params": [["(5000, 5000)", "(1000000, 10)"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b06d1af039ee49fcea92c1e11a041c293d33b86c73874976592036d57e966eb8", "warmup_time": -1}, "benchmarks.TimeDrop.time_drop": {"code": "class TimeDrop:\n    def time_drop(self, shape, axis, drop_ncols):\n        execute(self.df.drop(self.labels, axis))\n\n    def setup(self, shape, axis, drop_ncols):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        drop_count = (\n            int(len(self.df.axes[axis]) * drop_ncols)\n            if isinstance(drop_ncols, float)\n            else drop_ncols\n        )\n        self.labels = self.df.axes[axis][:drop_count]", "min_run_count": 2, "name": "benchmarks.TimeDrop.time_drop", "number": 0, "param_names": ["shape", "axis", "drop_ncols"], "params": [["(5000, 5000)", "(1000000, 10)"], ["0", "1"], ["1", "0.8"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cbeb16adcb3fadd00159e6c9922ccbfaac0eb086cd953d0eebb36b89c3e6e266", "warmup_time": -1}, "benchmarks.TimeFillna.time_fillna": {"code": "class TimeFillna:\n    def time_fillna(self, shape, limit, inplace):\n        kw = {\"value\": 0.0, \"limit\": self.limit, \"inplace\": inplace}\n        if inplace:\n            self.df.fillna(**kw)\n            execute(self.df)\n        else:\n            execute(self.df.fillna(**kw))\n\n    def setup(self, shape, limit, inplace):\n        pd = IMPL[ASV_USE_IMPL]\n        columns = [f\"col{x}\" for x in range(shape[1])]\n        self.df = pd.DataFrame(np.nan, index=pd.RangeIndex(shape[0]), columns=columns)\n        self.limit = int(limit * shape[0]) if limit else None", "min_run_count": 2, "name": "benchmarks.TimeFillna.time_fillna", "number": 0, "param_names": ["shape", "limit", "inplace"], "params": [["(5000, 5000)", "(1000000, 10)"], ["None", "0.8"], ["False", "True"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "24a895ac6bb572daba78946e1a36fa6506faf99ff85b15a830e08a44b46e7384", "warmup_time": -1}, "benchmarks.TimeGroupByDefaultAggregations.time_groupby_count": {"code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_count(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).count())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )", "min_run_count": 2, "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_count", "number": 0, "param_names": ["shape", "ngroups"], "params": [["(5000, 5000)", "(1000000, 10)"], ["100", "'huge_amount_groups'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "46a1f84a3f0c0b546f071c9be94866f953ddb6e2384a6ccbc518ad0b9154380c", "warmup_time": -1}, "benchmarks.TimeGroupByDefaultAggregations.time_groupby_mean": {"code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_mean(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).mean())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )", "min_run_count": 2, "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_mean", "number": 0, "param_names": ["shape", "ngroups"], "params": [["(5000, 5000)", "(1000000, 10)"], ["100", "'huge_amount_groups'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "23ad92017cdfe129d3ab99f79e62fe2722466cfac0a55179a1ecc00b910c4857", "warmup_time": -1}, "benchmarks.TimeGroupByDefaultAggregations.time_groupby_size": {"code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_size(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).size())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )", "min_run_count": 2, "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_size", "number": 0, "param_names": ["shape", "ngroups"], "params": [["(5000, 5000)", "(1000000, 10)"], ["100", "'huge_amount_groups'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f597a5f0dac5a4fabed5dd5548e9d73d8d39698a8437bf3466131cb18ed4dde5", "warmup_time": -1}, "benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum": {"code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_sum(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).sum())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )", "min_run_count": 2, "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum", "number": 0, "param_names": ["shape", "ngroups"], "params": [["(5000, 5000)", "(1000000, 10)"], ["100", "'huge_amount_groups'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ec74cb917a463fae4337b5d3444788e696f710113878e9df35417a0f56f92d09", "warmup_time": -1}, "benchmarks.TimeGroupByDictionaryAggregation.time_groupby_dict_agg": {"code": "class TimeGroupByDictionaryAggregation:\n    def time_groupby_dict_agg(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(self.agg_dict))\n\n    def setup(self, shape, ngroups, operation_type):\n        super().setup(shape, ngroups)\n        self.cols_to_agg = self.df.columns[1:4]\n        operations = self.operations[operation_type]\n        self.agg_dict = {\n            c: operations[i % len(operations)] for i, c in enumerate(self.cols_to_agg)\n        }", "min_run_count": 2, "name": "benchmarks.TimeGroupByDictionaryAggregation.time_groupby_dict_agg", "number": 0, "param_names": ["shape", "ngroups", "operation_type"], "params": [["(5000, 5000)", "(1000000, 10)"], ["100", "'huge_amount_groups'"], ["'reduction'", "'aggregation'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7aa41865cba30449bba2f4d9a40fe5d15e9d9b4c2c737222bd2a643fd6dcb39a", "warmup_time": -1}, "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean": {"code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_mean(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).apply(lambda df: df.mean()))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )", "min_run_count": 2, "name": "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean", "number": 0, "param_names": ["shape", "ngroups", "groupby_ncols"], "params": [["(5000, 5000)", "(1000000, 10)"], ["100", "'huge_amount_groups'"], ["6"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6584be7f02bda8d4601daf00fbd3fce226a7d4436faa6353a196619348047dea", "warmup_time": -1}, "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_quan": {"code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_quan(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(\"quantile\"))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )", "min_run_count": 2, "name": "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_quan", "number": 0, "param_names": ["shape", "ngroups", "groupby_ncols"], "params": [["(5000, 5000)", "(1000000, 10)"], ["100", "'huge_amount_groups'"], ["6"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "202444e83676d4998bfbfc58f218de93462f070c86e5000c628e56fb334193dc", "warmup_time": -1}, "benchmarks.TimeHead.time_head": {"code": "class TimeHead:\n    def time_head(self, shape, head_count):\n        execute(self.df.head(self.head_count))\n\n    def setup(self, shape, head_count):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        self.head_count = (\n            int(head_count * len(self.df.index))\n            if isinstance(head_count, float)\n            else head_count\n        )", "min_run_count": 2, "name": "benchmarks.TimeHead.time_head", "number": 0, "param_names": ["shape", "head_count"], "params": [["(5000, 5000)", "(1000000, 10)"], ["5", "0.8"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ab97d453eb88717822a7fbc0a43910d61e597489b0d1c49eec882656edd2dcf", "warmup_time": -1}, "benchmarks.TimeIndexing.time_iloc": {"code": "class TimeIndexing:\n    def time_iloc(self, shape, indexer_type):\n        execute(self.df.iloc[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        if indexer_type == \"bool\":\n            self.indexer = [False, True] * (shape[0] // 2)\n        elif indexer_type == \"scalar\":\n            self.indexer = shape[0] // 2\n        elif indexer_type == \"slice\":\n            self.indexer = slice(0, shape[0], 2)\n        elif indexer_type == \"list\":\n            self.indexer = [x for x in range(shape[0])]\n        elif indexer_type == \"function\":\n            self.indexer = lambda df: df.index[::-2]", "min_run_count": 2, "name": "benchmarks.TimeIndexing.time_iloc", "number": 0, "param_names": ["shape", "indexer_type"], "params": [["(5000, 5000)", "(1000000, 10)"], ["'scalar'", "'bool'", "'slice'", "'list'", "'function'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e7262aec0ddddcf2cf6befd225168aa1e9f52e0ebe945dc373d7bab9c5e494c", "warmup_time": -1}, "benchmarks.TimeIndexing.time_loc": {"code": "class TimeIndexing:\n    def time_loc(self, shape, indexer_type):\n        execute(self.df.loc[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        if indexer_type == \"bool\":\n            self.indexer = [False, True] * (shape[0] // 2)\n        elif indexer_type == \"scalar\":\n            self.indexer = shape[0] // 2\n        elif indexer_type == \"slice\":\n            self.indexer = slice(0, shape[0], 2)\n        elif indexer_type == \"list\":\n            self.indexer = [x for x in range(shape[0])]\n        elif indexer_type == \"function\":\n            self.indexer = lambda df: df.index[::-2]", "min_run_count": 2, "name": "benchmarks.TimeIndexing.time_loc", "number": 0, "param_names": ["shape", "indexer_type"], "params": [["(5000, 5000)", "(1000000, 10)"], ["'scalar'", "'bool'", "'slice'", "'list'", "'function'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7b6fd37f862f1a881d3f8e46bfd517d56f952ee9725a393f5c66ef88ba8a3a38", "warmup_time": -1}, "benchmarks.TimeInsert.time_insert_qc": {"code": "class TimeInsert:\n    def time_insert_qc(self, *args, **kwargs):\n        self.df.insert(loc=self.iloc, column=random_string(), value=self.item)\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)", "min_run_count": 2, "name": "benchmarks.TimeInsert.time_insert_qc", "number": 0, "param_names": ["shape", "item_length", "loc", "is_equal_indices"], "params": [["(5000, 5000)", "(1000000, 10)"], ["1"], ["'zero'", "'middle'", "'last'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6a36fc5cdb39f04cd6acb87bb95abcbb19bda4f85209e8d039c523287bdbf7a2", "warmup_time": -1}, "benchmarks.TimeInsert.time_insert_raw": {"code": "class TimeInsert:\n    def time_insert_raw(self, *args, **kwargs):\n        self.df.insert(loc=self.iloc, column=random_string(), value=self.item_raw)\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)", "min_run_count": 2, "name": "benchmarks.TimeInsert.time_insert_raw", "number": 0, "param_names": ["shape", "item_length", "loc", "is_equal_indices"], "params": [["(5000, 5000)", "(1000000, 10)"], ["1"], ["'zero'", "'middle'", "'last'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3df7c66b76b70618061bcfe51d0d0b9e10c21a48362cc453908a653cbe2fd176", "warmup_time": -1}, "benchmarks.TimeJoin.time_join": {"code": "class TimeJoin:\n    def time_join(self, shapes, how, sort):\n        # join dataframes on index to get the predictable shape\n        execute(self.df1.join(self.df2, how=how, lsuffix=\"left_\", sort=sort))\n\n    def setup(self, shapes, how, sort):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )", "min_run_count": 2, "name": "benchmarks.TimeJoin.time_join", "number": 0, "param_names": ["shapes", "how", "sort"], "params": [["((5000, 5000), (5000, 5000))", "((500000, 20), (1000000, 10))"], ["'left'", "'inner'"], ["False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1aebc2ab80819fc05dfc2e9db051894b755bc1f69150780b6a4541019f1728dc", "warmup_time": -1}, "benchmarks.TimeMerge.time_merge": {"code": "class TimeMerge:\n    def time_merge(self, shapes, how, sort):\n        # merge dataframes by index to get the predictable shape\n        execute(\n            self.df1.merge(\n                self.df2, left_index=True, right_index=True, how=how, sort=sort\n            )\n        )\n\n    def setup(self, shapes, how, sort):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )", "min_run_count": 2, "name": "benchmarks.TimeMerge.time_merge", "number": 0, "param_names": ["shapes", "how", "sort"], "params": [["((5000, 5000), (5000, 5000))", "((500000, 20), (1000000, 10))"], ["'left'", "'inner'"], ["False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5dd956fb7db1d5b0a96e59375c5e98318f9f43faa97b9b6562cf41d9445c9d9a", "warmup_time": -1}, "benchmarks.TimeMultiIndexing.time_multiindex_loc": {"code": "class TimeMultiIndexing:\n    def time_multiindex_loc(self, shape):\n        execute(\n            self.df.loc[\n                self.df.index[2] : self.df.index[-2],\n                self.df.columns[2] : self.df.columns[-2],\n            ]\n        )\n\n    def setup(self, shape):\n        df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n    \n        index = pd.MultiIndex.from_product([df.index[: shape[0] // 2], [\"bar\", \"foo\"]])\n        columns = pd.MultiIndex.from_product(\n            [df.columns[: shape[1] // 2], [\"buz\", \"fuz\"]]\n        )\n    \n        df.index = index\n        df.columns = columns\n    \n        self.df = df.sort_index(axis=1)", "min_run_count": 2, "name": "benchmarks.TimeMultiIndexing.time_multiindex_loc", "number": 0, "param_names": ["shape"], "params": [["(5000, 5000)", "(1000000, 10)"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "80e00dd183fe0c4a8126be25f72361ee20f99910b9769b7b35381e106e45dc4f", "warmup_time": -1}, "benchmarks.TimeProperties.time_columns": {"code": "class TimeProperties:\n    def time_columns(self, shape):\n        return self.df.columns\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)", "min_run_count": 2, "name": "benchmarks.TimeProperties.time_columns", "number": 0, "param_names": ["shape"], "params": [["(5000, 5000)", "(1000000, 10)"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "effb7b0976e7b3b0ee005ca8318ad48fb5588e1836d8ec6535810367e46725a8", "warmup_time": -1}, "benchmarks.TimeProperties.time_index": {"code": "class TimeProperties:\n    def time_index(self, shape):\n        return self.df.index\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)", "min_run_count": 2, "name": "benchmarks.TimeProperties.time_index", "number": 0, "param_names": ["shape"], "params": [["(5000, 5000)", "(1000000, 10)"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "487a3dbef05f696142e0534475d8373a9075dd28d31de0cf3449ca7a95ffb7b2", "warmup_time": -1}, "benchmarks.TimeProperties.time_shape": {"code": "class TimeProperties:\n    def time_shape(self, shape):\n        return self.df.shape\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)", "min_run_count": 2, "name": "benchmarks.TimeProperties.time_shape", "number": 0, "param_names": ["shape"], "params": [["(5000, 5000)", "(1000000, 10)"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b8ce432425cc9aa74975357694dfa8cb95a0553d19b8daf97522757a0a607904", "warmup_time": -1}, "benchmarks.TimeResetIndex.time_reset_index": {"code": "class TimeResetIndex:\n    def time_reset_index(self, shape, drop, level):\n        execute(self.df.reset_index(drop=drop, level=level))\n\n    def setup(self, shape, drop, level):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n    \n        if level:\n            index = pd.MultiIndex.from_product(\n                [self.df.index[: shape[0] // 2], [\"bar\", \"foo\"]],\n                names=[\"level_1\", \"level_2\"],\n            )\n            self.df.index = index", "min_run_count": 2, "name": "benchmarks.TimeResetIndex.time_reset_index", "number": 0, "param_names": ["shape", "drop", "level"], "params": [["(5000, 5000)", "(1000000, 10)"], ["False", "True"], ["None", "'level_1'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4ae1af8df03b9d41e917e8e6e18bd1eea483e80e35aa4f462ed1acee2f0a94a2", "warmup_time": -1}, "benchmarks.TimeSetItem.time_setitem_qc": {"code": "class TimeSetItem:\n    def time_setitem_qc(self, *args, **kwargs):\n        self.df[self.loc] = self.item\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)", "min_run_count": 2, "name": "benchmarks.TimeSetItem.time_setitem_qc", "number": 0, "param_names": ["shape", "item_length", "loc", "is_equal_indices"], "params": [["(5000, 5000)", "(1000000, 10)"], ["1"], ["'zero'", "'middle'", "'last'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1dcdd3d591970df5bad4e794a6b247d6b11cd6be21cf344809de06747fafbe17", "warmup_time": -1}, "benchmarks.TimeSetItem.time_setitem_raw": {"code": "class TimeSetItem:\n    def time_setitem_raw(self, *args, **kwargs):\n        self.df[self.loc] = self.item_raw\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)", "min_run_count": 2, "name": "benchmarks.TimeSetItem.time_setitem_raw", "number": 0, "param_names": ["shape", "item_length", "loc", "is_equal_indices"], "params": [["(5000, 5000)", "(1000000, 10)"], ["1"], ["'zero'", "'middle'", "'last'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6cae5f1f7d662915a35e36dc638b77707287a9bc5f67309f89f75fd57743ef01", "warmup_time": -1}, "benchmarks.TimeSortValues.time_sort_values": {"code": "class TimeSortValues:\n    def time_sort_values(self, shape, columns_number, ascending_list):\n        execute(self.df.sort_values(self.columns, ascending=self.ascending))\n\n    def setup(self, shape, columns_number, ascending_list):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        self.columns = random_columns(self.df.columns, columns_number)\n        self.ascending = (\n            random_booleans(columns_number)\n            if ascending_list\n            else bool(random_booleans(1)[0])\n        )", "min_run_count": 2, "name": "benchmarks.TimeSortValues.time_sort_values", "number": 0, "param_names": ["shape", "columns_number", "ascending_list"], "params": [["(5000, 5000)", "(1000000, 10)"], ["1", "2", "10", "100"], ["False", "True"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5cf2258ccb3d7833acd5e9765b8023fdbf0d27fd70e540f457f576be26c37ec9", "warmup_time": -1}, "benchmarks.TimeValueCountsFrame.time_value_counts": {"code": "class TimeValueCountsFrame:\n    def time_value_counts(self, *args, **kwargs):\n        execute(self.df.value_counts(subset=self.subset))\n\nclass BaseTimeValueCounts:\n    def setup(self, shape, ngroups=5, subset=\"all\"):\n        try:\n            subset = self.subset_params[subset]\n        except KeyError:\n            raise KeyError(\n                f\"Invalid value for 'subset={subset}'. Allowed: {list(self.subset_params.keys())}\"\n            )\n        ncols = subset(shape)\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, _ = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols=ncols,\n            count_groups=ngroups,\n        )\n        self.subset = self.df.columns[:ncols].tolist()", "min_run_count": 2, "name": "benchmarks.TimeValueCountsFrame.time_value_counts", "number": 0, "param_names": ["shape", "ngroups", "subset"], "params": [["(5000, 5000)", "(1000000, 10)"], ["100", "'huge_amount_groups'"], ["'all'", "'half'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "43e7bef1902e796ff3c180b27ae21d257541256bd187e7b8f59ed9b8dca07cd4", "warmup_time": -1}, "benchmarks.TimeValueCountsSeries.time_value_counts": {"code": "class TimeValueCountsSeries:\n    def time_value_counts(self, shape, ngroups, bins):\n        execute(self.df.value_counts(bins=bins))\n\n    def setup(self, shape, ngroups, bins):\n        super().setup(ngroups=ngroups, shape=shape)\n        self.df = self.df.iloc[:, 0]", "min_run_count": 2, "name": "benchmarks.TimeValueCountsSeries.time_value_counts", "number": 0, "param_names": ["shape", "ngroups", "bins"], "params": [["(5000, 5000)", "(1000000, 10)"], ["100", "'huge_amount_groups'"], ["None", "3"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cd8cd69d559c36bd90b816fcb0fb67588091a5ba8715a620666d07ace8e7c519", "warmup_time": -1}, "io.csv.TimeReadCsvNamesDtype.time_read_csv_names_dtype": {"code": "class TimeReadCsvNamesDtype:\n    def time_read_csv_names_dtype(self, cache, shape, names, dtype):\n        execute(\n            IMPL[ASV_USE_IMPL].read_csv(\n                self.filename,\n                names=self.names,\n                header=0,\n                dtype=self.dtype,\n                parse_dates=self.parse_dates,\n            )\n        )\n\n    def setup(self, cache, shape, names, dtype):\n        file_id = self._get_file_id(shape, dtype)\n        self.filename, self.names, self.dtype = cache[file_id]\n    \n        self.parse_dates = None\n        if dtype == \"Int64_Timestamp\":\n            # cached version of dtype should not change\n            self.dtype = self.dtype.copy()\n            for col in self._timestamp_columns:\n                del self.dtype[col]\n            self.parse_dates = self._timestamp_columns\n\n    def setup_cache(self, test_filename=\"io_test_file_csv_names_dtype\"):\n        # filenames with a metadata of saved dataframes\n        cache = {}\n        for shape in UNARY_OP_DATA_SIZE[ASV_DATASET_SIZE]:\n            for dtype in self._dtypes_params:\n                df = generate_dataframe(\"pandas\", \"int\", *shape, RAND_LOW, RAND_HIGH)\n                if dtype == \"Int64_Timestamp\":\n                    df = self._add_timestamp_columns(df)\n    \n                file_id = self._get_file_id(shape, dtype)\n                cache[file_id] = (\n                    f\"{test_filename}_{file_id}.csv\",\n                    df.columns.to_list(),\n                    df.dtypes.to_dict(),\n                )\n                df.to_csv(cache[file_id][0], index=False)\n        return cache", "min_run_count": 2, "name": "io.csv.TimeReadCsvNamesDtype.time_read_csv_names_dtype", "number": 0, "param_names": ["shape", "names", "dtype"], "params": [["(5000, 5000)", "(1000000, 10)"], ["'array-like'"], ["'Int64'", "'Int64_Timestamp'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/modin/asv_bench/benchmarks/io/csv.py:105", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6d9fdff5f8961d02d0843ec80266028f57a32a5aa14c55979377594b2641bf5e", "warmup_time": -1}, "io.csv.TimeReadCsvSkiprows.time_skiprows": {"code": "class TimeReadCsvSkiprows:\n    def time_skiprows(self, test_filenames, shape, skiprows):\n        execute(\n            IMPL[ASV_USE_IMPL].read_csv(\n                test_filenames[self.shape_id], skiprows=self.skiprows\n            )\n        )\n\n    def setup(self, test_filenames, shape, skiprows):\n        super().setup(test_filenames, shape, skiprows)\n        self.skiprows = self.skiprows_mapping[skiprows] if skiprows else None\n\nclass BaseReadCsv:\n    def setup_cache(self, test_filename=\"io_test_file\"):\n        test_filenames = {}\n        for shape in UNARY_OP_DATA_SIZE[ASV_DATASET_SIZE]:\n            shape_id = get_shape_id(shape)\n            test_filenames[shape_id] = f\"{test_filename}_{shape_id}.csv\"\n            df = generate_dataframe(\"pandas\", \"str_int\", *shape, RAND_LOW, RAND_HIGH)\n            df.to_csv(test_filenames[shape_id], index=False)\n    \n        return test_filenames", "min_run_count": 2, "name": "io.csv.TimeReadCsvSkiprows.time_skiprows", "number": 0, "param_names": ["shape", "skiprows"], "params": [["(5000, 5000)", "(1000000, 10)"], ["None", "'lambda_even_rows'", "'range_uniform'", "'range_step2'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "setup_cache_key": "/modin/asv_bench/benchmarks/io/csv.py:36", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f6ad8ffc075d605a25794b542b05d79b933743a4ad6bf416241dae3f6ec0bbe3", "warmup_time": -1}, "scalability.scalability_benchmarks.TimeFromPandas.time_from_pandas": {"code": "class TimeFromPandas:\n    def time_from_pandas(self, shape, cpus):\n        execute(from_pandas(self.data))\n\n    def setup(self, shape, cpus):\n        self.data = pandas.DataFrame(gen_data(\"int\", *shape, RAND_LOW, RAND_HIGH))\n        from modin.config import NPartitions\n    \n        NPartitions.get = lambda: cpus\n        # trigger ray init\n        pd.DataFrame([])", "min_run_count": 2, "name": "scalability.scalability_benchmarks.TimeFromPandas.time_from_pandas", "number": 0, "param_names": ["shape", "cpus"], "params": [["(5000, 5000)", "(1000000, 10)"], ["4", "16", "32"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8af06db97bd87859b17230125772585ddc3fe0c5e23426aca77776870540eab1", "warmup_time": -1}, "scalability.scalability_benchmarks.TimeToPandas.time_to_pandas": {"code": "class TimeToPandas:\n    def time_to_pandas(self, shape, cpus):\n        # to_pandas is already synchronous\n        to_pandas(self.data)\n\n    def setup(self, shape, cpus):\n        from modin.config import NPartitions\n    \n        NPartitions.get = lambda: cpus\n        self.data = generate_dataframe(\"modin\", \"int\", *shape, RAND_LOW, RAND_HIGH)", "min_run_count": 2, "name": "scalability.scalability_benchmarks.TimeToPandas.time_to_pandas", "number": 0, "param_names": ["shape", "cpus"], "params": [["(5000, 5000)", "(1000000, 10)"], ["4", "16", "32"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6e9561fb9fd503ccfe496c5c520304c983774eaabfbe0ec8958c49b39bdec972", "warmup_time": -1}}, "machines": {"xeon-e5": {"arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2699 v4 @ 2.20GHz", "machine": "xeon-e5", "num_cpu": "44", "os": "Linux 5.4.0-54-generic", "ram": "131910328", "version": 1}}, "tags": {"0.7.0": 554, "0.7.1": 582, "0.7.2": 589, "0.7.3": 696, "0.7.4": 1301, "0.8.0": 1518, "0.8.1": 2052, "0.8.1.1": 2055, "0.8.2": 2302, "0.8.3": 2616, "0.9.0": 3065, "Modin-v0.1.0": 29, "v0.1.1": 44, "v0.1.2": 52, "v0.2.0": 103, "v0.2.2": 119, "v0.2.3": 142, "v0.2.4": 147, "v0.2.5": 159, "v0.3.0": 246, "v0.3.0rc1": 233, "v0.3.1": 269, "v0.4.0": 284, "v0.4.0rc1": 278, "v0.5.0": 343, "v0.5.1": 356, "v0.5.2": 359, "v0.5.3": 380, "v0.5.4": 406, "v0.6.0": 428, "v0.6.1": 444, "v0.6.2": 457, "v0.6.3": 478}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}